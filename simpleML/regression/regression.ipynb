{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGS & PARAMS\n",
    "# if _user_selected_model is None:\n",
    "#     Execution_Id = \"output/{}/Job_{}_best_{}\".format(dataset_name, _id,datetime.datetime.now())\n",
    "# Pycaret Args\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown as md\n",
    "from pyfiglet import Figlet\n",
    "import datetime\n",
    "import yaml\n",
    "import os\n",
    "# Read YAML file\n",
    "with open(\"regression_config.yml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "for i,j in config.items():\n",
    "    if j == 'None':\n",
    "        config[i] = None\n",
    "               \n",
    "f = Figlet(font='slant')\n",
    "print (f.renderText('SimpleML'))\n",
    "\n",
    "print(\"Type : Linear Regression\")\n",
    "print(\"User : {}\".format(config['user_name']))\n",
    "print(\"Analysis name: {}_{}_{}\".format(config['analysis_name'], config['user_selected_model'], datetime.datetime.now().strftime (\"%Y%m%d\")))\n",
    "print(\"Model selection : {}\".format(config['user_selected_model']))\n",
    "start_date = datetime.datetime.now()\n",
    "print(\"Date time : {}\".format(start_date))\n",
    "\n",
    "\n",
    "\n",
    "# Create analysis folder\n",
    "\n",
    "try:\n",
    "    output_folder = \"{}/{}/{}/outputs/{}/\".format(config['user_name'], config['analysis_name'], config['user_selected_model'], start_date)\n",
    "    os.makedirs(output_folder)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "# backup config\n",
    "# from shutil import copyfile\n",
    "# copyfile(src, dst)\n",
    "#default dataset target variable mappings\n",
    "_default_target_variables = {'automobile':'price',\n",
    "'bike':'cnt',\n",
    "'boston':'medv',\n",
    "'concrete':'strength',\n",
    "'diamond':'Price',\n",
    "'forest':'area',\n",
    "'gold':'Gold_T',\n",
    "'house':'SalePrice',\n",
    "'insurance':'charges',\n",
    "'parkinsons','PPE',\n",
    "'traffic':'traffic_volume'}\n",
    "\n",
    "# Caret config\n",
    "if config['demo_run']:\n",
    "    _demo_dataset = config['demo_dataset']\n",
    "    _target = _default_target_variables[_demo_dataset]\n",
    "    _target_class = _default_target_variables[_demo_dataset]\n",
    "    print(\"Input data: {}\".format(config['demo_dataset']))\n",
    "else:\n",
    "    _input_file = config['input_file']\n",
    "    # Target processing\n",
    "    _target = config['target_variable'] # _target = 'medv' # default Target cclass for Boston data\n",
    "    _target_class = config['target_variable'] # _target_class = 'medv'\n",
    "    print(\"Input data : {}\".format(config['input_file']))\n",
    "_pandas_profiling = config['profile'] # _pandas_profiling = True # Default is True which gives detailed \n",
    "\n",
    "# Silent preprocessing should be True\n",
    "_silent_preprocessing = True # silent_preproccessing = True\n",
    "\n",
    "# Temp args\n",
    "if config['user_selected_model'] == 'Auto select best model':\n",
    "    _autoselect = True\n",
    "else:\n",
    "    _autoselect = False\n",
    "    \n",
    "_kfold = 10 # config['Kfolds'] # 10\n",
    "_round = 4\n",
    "if _autoselect:\n",
    "    _sort_best_model_by = config['auto_select_best_model_by'] # 'R2' #['R2']\n",
    "else:\n",
    "    _sort_best_model_by = \"R2\"\n",
    "_turbo = True\n",
    "_turbo = True\n",
    "_blacklist = None\n",
    "_user_selected_model = None\n",
    "_unseen_predictions = False\n",
    "# Now create model\n",
    "number_of_models = 1\n",
    "_auto_tune = config['auto_tune'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file:///Users/LMN/Documents/githubs/myCaret/simpleMl/auto_regression/your_report.html\n",
    "#md(f\"<a href='file:///Users/LMN/Documents/githubs/myCaret/simpleMl/auto_regression/your_report.html'>ds</a>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My ARGS\n",
    "\n",
    "# Pycaret Args\n",
    "# _input_file = None\n",
    "# _demo_dataset = 'boston'\n",
    "# _pandas_profiling = True # Default is True which gives detailed \n",
    "# _target = 'medv' # default Target cclass for Boston data\n",
    "# _silent_preproccessing = True\n",
    "import logging\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "# logging.debug(\"test\")\n",
    "# import the dataset from pycaret repository\n",
    "# logging.info(\"HELLLP\")\n",
    "import pandas as pd\n",
    "# if config['demo_run']:\n",
    "#     from pycaret.datasets import get_data\n",
    "#     input_data = get_data('boston', profile = True)\n",
    "#     data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "#     data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "#     print('Data for Modeling: ' + str(data.shape))\n",
    "#     print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "if _demo_dataset in ['boston']:\n",
    "    from pycaret.datasets import get_data\n",
    "    input_data = get_data(_demo_dataset)\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data\n",
    "else:\n",
    "    input_data = pd.read_csv(_input_file)\n",
    "    # print('No proper input was given, So running regression on Boston dataset')\n",
    "    logging.info('Succesfully read the input csv')\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preprocessing and EDA\n",
    "\n",
    "pre-processing steps (other than those that are imperative for machine learning experiments which were performed \n",
    "automatically). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _target_class = 'medv'\n",
    "# _normalize = True\n",
    "# _transformation = True\n",
    "# _transform_target = True\n",
    "# _combine_rare_levels = True\n",
    "# _rare_level_threshold = 0.05\n",
    "# _remove_multicollinearity = True\n",
    "# _multicollinearity_threshold = 0.95\n",
    "# _bin_numeric_features = []\n",
    "# _silent_preproccessing = True\n",
    "from pycaret.regression import *\n",
    "\n",
    "exp_reg102 = setup(data = input_data, target = _target,\n",
    "train_size = float(config['train_size']),\n",
    "sampling = config['sampling'],\n",
    "sample_estimator = config['sample_estimator'],\n",
    "categorical_features = config['categorical_features'],\n",
    "categorical_imputation = config['categorical_imputation'],\n",
    "ordinal_features = config['ordinal_features'],\n",
    "high_cardinality_features = config['high_cardinality_features'] ,\n",
    "high_cardinality_method = config['high_cardinality_method'] ,\n",
    "numeric_features = config['numeric_features'],\n",
    "numeric_imputation = config['numeric_imputation'],\n",
    "date_features = config['date_features'] ,\n",
    "ignore_features = config['ignore_features'] ,\n",
    "normalize =config['normalize'] ,\n",
    "normalize_method = config['normalize_method'],\n",
    "transformation = config['transformation'],\n",
    "transformation_method = config['transformation_method'],\n",
    "handle_unknown_categorical = config['handle_unknown_categorical'],\n",
    "unknown_categorical_method = config['unknown_categorical_method'],\n",
    "pca = config['pca'],\n",
    "pca_method = config['pca_method'] ,\n",
    "pca_components = float(config['pca_components']) ,\n",
    "ignore_low_variance = config['ignore_low_variance'],\n",
    "combine_rare_levels = config['combine_rare_levels'],\n",
    "rare_level_threshold = float(config['rare_level_threshold']),\n",
    "bin_numeric_features = config['bin_numeric_features'],\n",
    "remove_outliers = config['remove_outliers'],\n",
    "outliers_threshold = float(config['outliers_threshold']),\n",
    "remove_multicollinearity = config['remove_multicollinearity'], \n",
    "multicollinearity_threshold = float(config['multicollinearity_threshold']),\n",
    "create_clusters = config['create_clusters'], \n",
    "cluster_iter = int(config['cluster_iter']), \n",
    "polynomial_features = config['polynomial_features'], \n",
    "polynomial_degree = int(config['polynomial_degree']), \n",
    "trigonometry_features = config['trigonometry_features'], \n",
    "polynomial_threshold = float(config['polynomial_threshold']), \n",
    "group_features = config['group_features'], \n",
    "group_names = config['group_names'], \n",
    "feature_selection = config['feature_selection'], \n",
    "feature_selection_threshold = float(config['feature_selection_threshold']), \n",
    "feature_interaction = config['feature_interaction'], \n",
    "feature_ratio = config['feature_ratio'], \n",
    "interaction_threshold = float(config['interaction_threshold']),\n",
    "transform_target = config['transform_target'], \n",
    "transform_target_method = 'box-cox', \n",
    "session_id = config['session_id'], \n",
    "silent=_silent_preprocessing, \n",
    "profile = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all Models\n",
    "Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using k-fold cross validation for metric evaluation. The output prints a score grid that shows average MAE, MSE, RMSE, R2, RMSLE and MAPE accross the folds (10 by default) of all the available models in the model library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temp args\n",
    "# _autoselect = True\n",
    "# _kfold = 10\n",
    "# _round = 4\n",
    "# _sort_best_model_by = 'R2' #['R2']\n",
    "# _turbo = True\n",
    "# _blacklist = None\n",
    "# _user_selected_model = None\n",
    "models_comparison = compare_models(blacklist = _blacklist, fold = config['Kfolds'],  round = _round,  sort = _autoselect, turbo = _turbo)\n",
    "models_comparison.to_excel('{}/tmp_models.xlsx'.format(output_folder))\n",
    "models_comparison_df = pd.read_excel('{}/tmp_models.xlsx'.format(output_folder),index = False)\n",
    "display(models_comparison)\n",
    "best_model = models_comparison_df['Model'][0]\n",
    "top_five_best_models = models_comparison_df['Model'][0:5]\n",
    "top_three_best_models = models_comparison_df['Model'][0:3]\n",
    "print(\"Best suggested model based on best value for {} is {}\".format(best_model, _sort_best_model_by))\n",
    "if _user_selected_model is not None:\n",
    "    print('Model of interest is selected {}'.format(_user_selected_model))\n",
    "\n",
    "if _autoselect == True or _user_selected_model is None:\n",
    "    model_selected = best_model\n",
    "    print(\"Selected {} based on {}\".format(best_model, _sort_best_model_by))\n",
    "else:\n",
    "    model_selected = _user_selected_model\n",
    "    print(\"Selected {} based on user choice\".format(model_selected))\n",
    "\n",
    "#print(\"model stats for {}: DF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score grid printed above highlights the highest performing metric for comparison purposes only. The grid by default is sorted using R2 (highest to lowest) which can be changed by passing sort parameter. For example compare_models(sort = 'RMSLE') will sort the grid by RMSLE (lower to higher since lower is better). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create model\n",
    "number_of_models = 1\n",
    "\n",
    "\n",
    "def model_to_abv(model):\n",
    "    abvs = {'Linear Regression':'lr',\n",
    "'Lasso Regression':'lasso',\n",
    "'Ridge Regression':'ridge',\n",
    "'Elastic Net':'en',\n",
    "'Least Angle Regression':'lar',\n",
    "'Lasso Least Angle Regression':'llar',\n",
    "'Orthogonal Matching Pursuit':'omp',\n",
    "'Bayesian Ridge':'br',\n",
    "'Automatic Relevance Determination':'ard',\n",
    "'Passive Aggressive Regressor':'par',\n",
    "'Random Sample Consensus':'ransac',\n",
    "'TheilSen Regressor':'tr',\n",
    "'Huber Regressor':'huber',\n",
    "'Kernel Ridge':'kr',\n",
    "'Support Vector Machine':'svm',\n",
    "'K Neighbors Regressor':'knn',\n",
    "'Decision Tree':'dt',\n",
    "'Random Forest':'rf',\n",
    "'Extra Trees Regressor':'et',\n",
    "'AdaBoost Regressor':'ada',\n",
    "'Gradient Boosting Regressor':'gbr',\n",
    "'Multi Level Perceptron':'mlp',\n",
    "'Extreme Gradient Boosting':'xgboost',\n",
    "'Light Gradient Boosting':'lightgbm',\n",
    "'CatBoost Regressor':'catboost'}\n",
    "    return abvs[model]\n",
    "\n",
    "def train_and_plot_model(model, _auto_tune, plots = True):\n",
    "    print(\"Training {}\".format(model))\n",
    "    if _auto_tune:\n",
    "        print('Training with default hyper parameters')\n",
    "        trained_model = tune_model(model_to_abv(model))\n",
    "        print(\"Completed trained with default hyperparameters tuned {}\".format(trained_model))\n",
    "    else:\n",
    "        print(\"Hyperparameter tuning... {}\".format(_auto_tune))\n",
    "        trained_model = create_model(model_to_abv(model))\n",
    "        print(\"Completed training with hyperparameters tuned {}\".format(trained_model))\n",
    "    return trained_model \n",
    "trained_model = train_and_plot_model(model_selected,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(trained_model)\n",
    "model_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = True\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print('Hyper parameters')\n",
    "    display(plot_model(trained_model, plot = 'parameter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "# Residual Plot\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print('Residual plots')\n",
    "    print(plot_model(trained_model))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"Feature importance plot\")\n",
    "    plot_model(trained_model, plot = 'feature')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Error Plot\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"Prediction Error plot\")\n",
    "    plot_model(trained_model, plot = 'error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"Learning Curve plot\")\n",
    "    display(plot_model(trained_model, plot = 'learning'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recursive Feature Selection\n",
    "# print(\"Recursive Feature Selection\")\n",
    "# plot_model(trained_model, plot = 'rfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooks Distance Plot\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"Cooks Distance Plot\")\n",
    "    plot_model(trained_model, plot = 'cooks')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Curve Plot\n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"Validation Curve Plot\")\n",
    "    display(plot_model(trained_model, plot = 'vc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manifold \n",
    "if plots == True and model_selected not in ['CatBoost Regressor']:\n",
    "    print(\"manifold\")\n",
    "    display(plot_model(trained_model, plot = 'manifold'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interpret_model(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalized Model for Deployment\n",
    "Model fit onto the complete dataset including the test/hold-out sample (30% by default). The purpose of this function is to train the model on the complete dataset before it is deployed in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = finalize_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuraccies/metrics of model on test/hold-out sample sets are shown below')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = predict_model(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _unseen_predictions:\n",
    "    md(f\"#### Prediction on Unseen Data\")\n",
    "    unseen_predictions = predict_model(final_model, data=data_unseen)\n",
    "    unseen_predictions.head()\n",
    "    unseen_predictions_file = '{}unseen_prediction.csv'.format(output_folder)\n",
    "    unseen_predictions.to_csv(unseen_predictions_file)\n",
    "    print('Exported {}'.format(unseen_predictions_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save the model / Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pickling model to {}\".format(output_folder))\n",
    "save_model(final_model,'{}FinalModel'.format(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
