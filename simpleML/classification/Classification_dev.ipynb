{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown as md\n",
    "from pyfiglet import Figlet\n",
    "import datetime\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read YAML file\n",
    "with open(\"classification_config.yml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "# Convert 'None' to None\n",
    "for i,j in config.items():\n",
    "    if j == 'None':\n",
    "        config[i] = None\n",
    "               \n",
    "f = Figlet(font='slant')\n",
    "print (f.renderText('SimpleML'))\n",
    "print(\"Type : Classification\")\n",
    "print(\"User : {}\".format(config['user_name']))\n",
    "print(\"Analysis name: {}_{}_{}\".format(config['analysis_name'], config['user_selected_model'], datetime.datetime.now().strftime (\"%Y%m%d\")))\n",
    "print(\"Model selection : {}\".format(config['user_selected_model']))\n",
    "start_date = datetime.datetime.now()\n",
    "print(\"Date time : {}\".format(start_date))\n",
    "\n",
    "# Create analysis folder\n",
    "try:\n",
    "    output_folder = \"{}/{}/{}/outputs/{}/\".format(config['user_name'], config['analysis_name'], config['user_selected_model'], start_date)\n",
    "    os.makedirs(output_folder)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "# default demo dataset target variable mappings\n",
    "_default_target_variables = {'credit':'default', 'blood':'Class',\n",
    "'cancer':'Class', 'diabetes':'Class', 'heart':'DEATH', 'hepatitis':'Class',\n",
    "'parkinsons':'PPE', 'wine':'traffic_volume', 'heart_disease':'type'}\n",
    "\n",
    "# Caret config\n",
    "if config['demo_run']:\n",
    "    _demo_dataset = config['demo_dataset']\n",
    "    _target = _default_target_variables[_demo_dataset]\n",
    "    _target_class = _default_target_variables[_demo_dataset]\n",
    "    print(\"Input data: {}\".format(config['demo_dataset']))\n",
    "else:\n",
    "    _input_file = config['input_file']\n",
    "    # Target processing\n",
    "    _target = config['target_variable'] # _target = 'medv' # default Target cclass for Boston data\n",
    "    _target_class = config['target_variable'] # _target_class = 'medv'\n",
    "    print(\"Input data : {}\".format(config['input_file']))\n",
    "_pandas_profiling = config['profile'] # _pandas_profiling = True # Default is True which gives detailed \n",
    "\n",
    "# Silent preprocessing should be True unfortunately\n",
    "_silent_preprocessing = True # silent_preproccessing = True\n",
    "\n",
    "# Temp args\n",
    "if config['user_selected_model'] == 'Auto select best model':\n",
    "    _autoselect = True\n",
    "else:\n",
    "    _autoselect = False\n",
    "    \n",
    "_kfold = 10 # config['Kfolds'] # 10\n",
    "_round = 4\n",
    "if _autoselect:\n",
    "    _sort_best_model_by = config['auto_select_best_model_by'] # 'R2' #['R2']\n",
    "else:\n",
    "    _sort_best_model_by = \"Accuracy\"\n",
    "_turbo = True\n",
    "_blacklist = None\n",
    "_user_selected_model = None\n",
    "_unseen_predictions = False\n",
    "# Now create model\n",
    "number_of_models = 1\n",
    "_auto_tune = config['auto_tune'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "dataset = get_data('credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset.sample(frac=0.95, random_state=786).reset_index(drop=True)\n",
    "# data_unseen = dataset.drop(data.index).reset_index(drop=True)\n",
    "# print('Data for Modeling: ' + str(data.shape))\n",
    "# print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "# Configure Inputs & Test sets\n",
    "if _demo_dataset in ['credit', 'blood', 'cancer', 'diabetes', 'heart', 'hepatitis', 'parkinsons', 'wine', 'heart_disease']:\n",
    "    from pycaret.datasets import get_data\n",
    "    input_data = get_data(_demo_dataset)\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data\n",
    "else:\n",
    "    input_data = pd.read_csv(_input_file)\n",
    "    # print('No proper input was given, So running regression on Boston dataset')\n",
    "    logging.info('Succesfully read the input csv')\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccessing and EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_classification = setup(data = data, target = _target,\n",
    "train_size = float(config['train_size']),\n",
    "sampling = config['sampling'],\n",
    "sample_estimator = config['sample_estimator'],\n",
    "categorical_features = config['categorical_features'],\n",
    "categorical_imputation = config['categorical_imputation'],\n",
    "ordinal_features = config['ordinal_features'],\n",
    "high_cardinality_features = config['high_cardinality_features'] ,\n",
    "high_cardinality_method = config['high_cardinality_method'] ,\n",
    "numeric_features = config['numeric_features'],\n",
    "numeric_imputation = config['numeric_imputation'],\n",
    "date_features = config['date_features'] ,\n",
    "ignore_features = config['ignore_features'] ,\n",
    "normalize =config['normalize'] ,\n",
    "normalize_method = config['normalize_method'],\n",
    "handle_unknown_categorical = config['handle_unknown_categorical'],\n",
    "unknown_categorical_method = config['unknown_categorical_method'],\n",
    "pca = config['pca'],\n",
    "pca_method = config['pca_method'] ,\n",
    "pca_components = float(config['pca_components']) ,\n",
    "ignore_low_variance = config['ignore_low_variance'],\n",
    "combine_rare_levels = config['combine_rare_levels'],\n",
    "rare_level_threshold = float(config['rare_level_threshold']),\n",
    "bin_numeric_features = config['bin_numeric_features'],\n",
    "remove_outliers = config['remove_outliers'],\n",
    "outliers_threshold = float(config['outliers_threshold']),\n",
    "remove_multicollinearity = config['remove_multicollinearity'], \n",
    "multicollinearity_threshold = float(config['multicollinearity_threshold']),\n",
    "create_clusters = config['create_clusters'], \n",
    "cluster_iter = int(config['cluster_iter']), \n",
    "polynomial_features = config['polynomial_features'], \n",
    "polynomial_degree = int(config['polynomial_degree']), \n",
    "trigonometry_features = config['trigonometry_features'], \n",
    "polynomial_threshold = float(config['polynomial_threshold']), \n",
    "group_features = config['group_features'], \n",
    "group_names = config['group_names'], \n",
    "feature_selection = config['feature_selection'], \n",
    "feature_selection_threshold = float(config['feature_selection_threshold']), \n",
    "feature_interaction = config['feature_interaction'], \n",
    "feature_ratio = config['feature_ratio'], \n",
    "interaction_threshold = float(config['interaction_threshold']),\n",
    "session_id = config['session_id'], \n",
    "silent=_silent_preprocessing, \n",
    "profile = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance using metrics available\n",
    "models_comparison = compare_models(blacklist = _blacklist, fold = config['Kfolds'],  round = _round,  sort = _sort_best_model_by, turbo = _turbo)\n",
    "models_comparison.to_excel('{}/tmp_models.xlsx'.format(output_folder))\n",
    "models_comparison_df = pd.read_excel('{}/tmp_models.xlsx'.format(output_folder),index = False)\n",
    "display(models_comparison)\n",
    "best_model = models_comparison_df['Model'][0]\n",
    "top_five_best_models = models_comparison_df['Model'][0:5]\n",
    "top_three_best_models = models_comparison_df['Model'][0:3]\n",
    "print(\"Best suggested model based on best value for {} is {}\".format(best_model, _sort_best_model_by))\n",
    "if _user_selected_model is not None:\n",
    "    print('Model of interest is selected {}'.format(_user_selected_model))\n",
    "\n",
    "if _autoselect == True or _user_selected_model is None:\n",
    "    model_selected = best_model\n",
    "    print(\"Selected {} based on {}\".format(best_model, _sort_best_model_by))\n",
    "else:\n",
    "    model_selected = _user_selected_model\n",
    "    print(\"Selected {} based on user choice\".format(model_selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected models training results & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create model\n",
    "number_of_models = 1\n",
    "\n",
    "def model_to_abv(model):\n",
    "    abvs = {'Logistic Regression':'lr',\n",
    "'K Nearest Neighbour':'knn',\n",
    "'Naives Bayes':'nb',\n",
    "\"Decision Tree\":'dt',\n",
    "'SVM (Linear)':'svm',\n",
    "'SVM (RBF)':'rbfsvm',\n",
    "'Gaussian Process':'gpc',\n",
    "'Multi Level Perceptron':'mlp',\n",
    "\"Ridge Classifier\":'ridge',\n",
    "\"Random Forest\":'rf',\n",
    "\"Quadratic Disc. Analysis\":'qda',\n",
    "\"AdaBoost\":'ada',\n",
    "\"Gradient Boosting Classifier\":'gbc',\n",
    "\"Linear Discriminant Analysis\" : 'lda',\n",
    "\"Extra Trees Classifier\" :'et',\n",
    "\"Extreme Gradient Boosting\":'xgboost',\n",
    "\"Light Gradient Boosting\": 'lightgbm',\n",
    "\"Cat Boost Classifier\":'catboost'}\n",
    "    return abvs[model]\n",
    "\n",
    "def train_and_plot_model(model, _auto_tune, plots = True):\n",
    "    print(\"Training {}\".format(model))\n",
    "    if _auto_tune:\n",
    "        print('Training with default hyper parameters')\n",
    "        trained_model = tune_model(model_to_abv(model))\n",
    "        print(\"Completed trained with default hyperparameters tuned {}\".format(trained_model))\n",
    "    else:\n",
    "        print(\"Hyperparameter tuning... {}\".format(_auto_tune))\n",
    "        trained_model = create_model(model_to_abv(model))\n",
    "        print(\"Completed training with hyperparameters tuned {}\".format(trained_model))\n",
    "    return trained_model \n",
    "trained_model = train_and_plot_model(model_selected,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_to_abv(model_selected) not in ['svm', 'ridge']:\n",
    "    md(f\"AUC Curve\")\n",
    "    plot_model(trained_model, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f\"Precision Recall\")\n",
    "plot_model(trained_model, plot = 'pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Confusion Matrix')\n",
    "plot_model(trained_model, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Discrimination Threshold')\n",
    "plot_model(trained_model, plot = 'threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Class Prediction Error')\n",
    "plot_model(trained_model, plot = 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Classification Report')\n",
    "plot_model(trained_model, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Decision Boundary')\n",
    "plot_model(trained_model, plot = 'boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEED TO FIGURE OUT SUPPORTED ALGOs\n",
    "# print('Recursive Feature Selection')\n",
    "# plot_model(trained_model, 'rfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Learning Curve')\n",
    "plot_model(trained_model, plot = 'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEED TO FIGURE OUT SUPPORTED ALGOs\n",
    "# print('Manifold Learning')\n",
    "# plot_model(trained_model, plot ='manifold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEED TO FIGURE OUT SUPPORTED ALGOs\n",
    "# print('Calibration Curve')\n",
    "# plot_model(trained_model, plot = 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Validation Curve')\n",
    "plot_model(trained_model, plot ='vc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Dimension Learning')\n",
    "plot_model(trained_model, plot ='dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Feature Importance')\n",
    "plot_model(trained_model, plot ='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'Model Hyperparameter')\n",
    "plot_model(trained_model, plot ='parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # TODO NEED TO FIGURE OUT SUPPORTED ALGOs\n",
    "    interpret_model(trained_model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "pm = predict_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize model\n",
    "final_model = finalize_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "unseen_predictions = predict_model(final_model, data=data_unseen)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pickling model to {}\".format(output_folder))\n",
    "save_model(final_model,'{}FinalModel'.format(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
