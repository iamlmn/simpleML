{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown as md\n",
    "from pyfiglet import Figlet\n",
    "import datetime\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Read config YAML file\n",
    "with open(\"clustering_config.yml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "# Convert string 'None' to None variables.\n",
    "for i,j in config.items():\n",
    "    if j == 'None':\n",
    "        config[i] = None\n",
    "               \n",
    "f = Figlet(font='slant')\n",
    "print (f.renderText('SimpleML'))\n",
    "print(\"Type : Clustering\")\n",
    "print(\"User : {}\".format(config['user_name']))\n",
    "print(\"Analysis name: {}_{}_{}\".format(config['analysis_name'], config['user_selected_model'], datetime.datetime.now().strftime (\"%Y%m%d\")))\n",
    "print(\"Model selection : {}\".format(config['user_selected_model']))\n",
    "start_date = datetime.datetime.now()\n",
    "print(\"Date time : {}\".format(start_date))\n",
    "\n",
    "# Create analysis folder\n",
    "try:\n",
    "    output_folder = \"{}/{}/{}/outputs/{}/\".format(config['user_name'], config['analysis_name'], config['user_selected_model'], start_date)\n",
    "    os.makedirs(output_folder)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "# #default dataset target variable mappings for demo datasets\n",
    "# _default_target_variables = {'automobile':'price',\n",
    "# 'bike':'cnt',\n",
    "# 'boston':'medv',\n",
    "# 'concrete':'strength',\n",
    "# 'diamond':'Price',\n",
    "# 'forest':'area',\n",
    "# 'gold':'Gold_T',\n",
    "# 'house':'SalePrice',\n",
    "# 'insurance':'charges',\n",
    "# 'parkinsons','PPE',\n",
    "# 'traffic':'traffic_volume'}\n",
    "\n",
    "# SimpleML config\n",
    "if config['demo_run']:\n",
    "    _demo_dataset = config['demo_dataset']\n",
    "    _target = _default_target_variables[_demo_dataset]\n",
    "    _target_class = _default_target_variables[_demo_dataset]\n",
    "    print(\"Input data: {}\".format(config['demo_dataset']))\n",
    "else:\n",
    "    _input_file = config['input_file']\n",
    "    # Target processing\n",
    "    _target = config['target_variable'] # _target = 'medv' # default Target cclass for Boston data\n",
    "    _target_class = config['target_variable'] # _target_class = 'medv'\n",
    "    print(\"Input data : {}\".format(config['input_file']))\n",
    "_pandas_profiling = config['profile'] # _pandas_profiling = True # Default is True which gives detailed \n",
    "\n",
    "# Silent preprocessing should be True\n",
    "_silent_preprocessing = True # silent_preproccessing = True\n",
    "\n",
    "# Temp args\n",
    "if config['user_selected_model'] == 'Auto select best model':\n",
    "    _autoselect = True\n",
    "else:\n",
    "    _autoselect = False\n",
    "    \n",
    "_kfold = 10 # config['Kfolds'] # 10\n",
    "_round = 4\n",
    "if _autoselect:\n",
    "    _sort_best_model_by = config['auto_select_best_model_by'] # 'R2' #['R2']\n",
    "else:\n",
    "    _sort_best_model_by = \"R2\"\n",
    "_turbo = True\n",
    "_turbo = True\n",
    "_blacklist = None\n",
    "_user_selected_model = None\n",
    "_unseen_predictions = False\n",
    "# Now create model config\n",
    "number_of_models = 1\n",
    "_auto_tune = config['auto_tune'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Inputs & Test sets\n",
    "if _demo_dataset in ['boston']:\n",
    "    from pycaret.datasets import get_data\n",
    "    input_data = get_data(_demo_dataset)\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data\n",
    "else:\n",
    "    input_data = pd.read_csv(_input_file)\n",
    "    # print('No proper input was given, So running regression on Boston dataset')\n",
    "    logging.info('Succesfully read the input csv')\n",
    "    if _unseen_predictions:\n",
    "        data = input_data.sample(frac=0.9, random_state=786).reset_index(drop=True)\n",
    "        data_unseen = input_data.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "        print('Data for Modeling: ' + str(data.shape))\n",
    "        print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "    else:\n",
    "        data = input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preprocessing and EDA\n",
    "\n",
    "pre-processing steps (other than those that are imperative for machine learning experiments which were performed \n",
    "automatically). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & ED\n",
    "from pycaret.clustering import *\n",
    "\n",
    "exp_clu101 = setup(data, normalize = True, \n",
    "                   ignore_features = ['MouseID'],\n",
    "                   session_id = 123, profile = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANALYZE RESULTS\n",
    "Now that we have created a model, we would like to assign the cluster labels to our dataset (1080 samples) to analyze the results. We will achieve this by using the assign_model() function. See an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_results = assign_model(kmeans)\n",
    "kmean_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score grid printed above highlights the highest performing metric for comparison purposes only. The grid by default is sorted using R2 (highest to lowest) which can be changed by passing sort parameter. For example compare_models(sort = 'RMSLE') will sort the grid by RMSLE (lower to higher since lower is better). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c0ad881d8b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completed training with hyperparameters tuned {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_plot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_selected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_selected' is not defined"
     ]
    }
   ],
   "source": [
    "# Now create model\n",
    "number_of_models = 1\n",
    "\n",
    "# Train User selected or auto selected best model\n",
    "def model_to_abv(model):\n",
    "    abvs = {'K-Means Clustering':'kmeans',\n",
    "'Affinity Propagation':'ap',\n",
    "'Mean shift Clustering':'meanshift',\n",
    "'Spectral Clustering':'sc',\n",
    "'Agglomerative Clustering':'hclust',\n",
    "'Density-Based Spatial Clustering':'dbscan',\n",
    "'OPTICS Clustering':'optics',\n",
    "'Birch Clustering':'birch',\n",
    "'K-Modes Clustering':'kmodes'}\n",
    "    return abvs[model]\n",
    "\n",
    "def train_and_plot_model(model, _auto_tune, plots = True):\n",
    "    print(\"Training {}\".format(model))\n",
    "    if _auto_tune:\n",
    "        print('Training with default hyper parameters')\n",
    "        trained_model = tune_model(model_to_abv(model))\n",
    "        print(\"Completed trained with default hyperparameters tuned {}\".format(trained_model))\n",
    "    else:\n",
    "        print(\"Hyperparameter tuning... {}\".format(_auto_tune))\n",
    "        trained_model = create_model(model_to_abv(model))\n",
    "        print(\"Completed training with hyperparameters tuned {}\".format(trained_model))\n",
    "    return trained_model \n",
    "trained_model = train_and_plot_model(model_selected,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster PCA Plot\n",
    "plot_model(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow\n",
    "plot_model(kmeans, plot = 'elbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sillouhete\n",
    "plot_model(kmeans, plot = 'silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plit\n",
    "plot_model(kmeans, plot = 'distribution') #to see size of clusters\n",
    "# plot_model(kmeans, plot = 'distribution', feature = 'class')\n",
    "# plot_model(kmeans, plot = 'distribution', feature = 'CaNA_N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unseens predictioins\n",
    "unseen_predictions = predict_model(kmeans, data=data_unseen)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(kmeans,'Final Kmeans Model 08Feb2020')\n",
    "\n",
    "# saved_kmeans = load_model('Final Kmeans Model 08Feb2020')\n",
    "# new_prediction = predict_model(saved_kmeans, data=data_unseen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
